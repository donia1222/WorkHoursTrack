import * as FileSystem from 'expo-file-system';

export interface ImageAnalysisResult {
  text?: string;
  labels?: Array<{
    description: string;
    score: number;
  }>;
  objects?: Array<{
    name: string;
    score: number;
  }>;
  error?: string;
}

export class GoogleVisionService {
  private static readonly API_KEY = process.env.EXPO_PUBLIC_GOOGLE_API_KEY;
  private static readonly VISION_BASE_URL = 'https://vision.googleapis.com/v1/images:annotate';
  private static readonly GEMINI_BASE_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent';
  private static readonly GEMINI_VISION_BASE_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-vision:generateContent';

  static async analyzeImage(imageUri: string, features: string[] = ['TEXT_DETECTION', 'LABEL_DETECTION']): Promise<ImageAnalysisResult> {
    try {
      if (!this.API_KEY) {
        throw new Error('Google API key no configurada');
      }

      // Convertir imagen a base64
      const base64Image = await FileSystem.readAsStringAsync(imageUri, {
        encoding: FileSystem.EncodingType.Base64,
      });

      // Preparar request para Google Vision API
      const requestBody = {
        requests: [
          {
            image: {
              content: base64Image,
            },
            features: features.map(feature => ({
              type: feature,
              maxResults: 10,
            })),
          },
        ],
      };

      const response = await fetch(`${this.VISION_BASE_URL}?key=${this.API_KEY}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        throw new Error(`Error en la API: ${response.status}`);
      }

      const data = await response.json();
      
      if (data.responses?.[0]?.error) {
        throw new Error(data.responses[0].error.message);
      }

      const result: ImageAnalysisResult = {};
      const annotations = data.responses?.[0];

      // Extraer texto detectado
      if (annotations?.textAnnotations?.length > 0) {
        result.text = annotations.textAnnotations[0].description;
      }

      // Extraer etiquetas/labels
      if (annotations?.labelAnnotations?.length > 0) {
        result.labels = annotations.labelAnnotations.map((label: any) => ({
          description: label.description,
          score: label.score,
        }));
      }

      // Extraer objetos detectados
      if (annotations?.localizedObjectAnnotations?.length > 0) {
        result.objects = annotations.localizedObjectAnnotations.map((obj: any) => ({
          name: obj.name,
          score: obj.score,
        }));
      }

      return result;
    } catch (error) {
      console.error('Error analizando imagen:', error);
      return {
        error: error instanceof Error ? error.message : 'Error desconocido',
      };
    }
  }

  static async extractTextOnly(imageUri: string): Promise<string> {
    const result = await this.analyzeImage(imageUri, ['TEXT_DETECTION']);
    return result.text || result.error || 'No se detect√≥ texto en la imagen';
  }

  static async getImageDescription(imageUri: string): Promise<string> {
    console.log('üîç [VISION] Iniciando an√°lisis completo de imagen...');
    
    // Hacer an√°lisis completo: OCR + detecci√≥n de objetos + etiquetas
    const result = await this.analyzeImage(imageUri, ['TEXT_DETECTION', 'LABEL_DETECTION', 'OBJECT_LOCALIZATION']);
    
    if (result.error) {
      console.error('‚ùå [VISION] Error en an√°lisis:', result.error);
      return `Error: ${result.error}`;
    }

    let description = 'üìã **AN√ÅLISIS COMPLETO DE LA IMAGEN:**\n\n';
    
    // PRIMERO: Texto extra√≠do (lo m√°s importante para planes de trabajo)
    if (result.text && result.text.trim()) {
      console.log('üìù [VISION] Texto extra√≠do:', result.text);
      description += 'üìù **TEXTO DETECTADO:**\n';
      description += `${result.text}\n\n`;
    } else {
      console.log('‚ö†Ô∏è [VISION] No se detect√≥ texto legible');
      description += '‚ö†Ô∏è **TEXTO:** No se detect√≥ texto legible en la imagen\n\n';
    }
    
    // SEGUNDO: Elementos generales (contexto adicional)
    if (result.labels && result.labels.length > 0) {
      description += 'üè∑Ô∏è **ELEMENTOS DETECTADOS:**\n';
      result.labels
        .filter(label => label.score > 0.5)
        .slice(0, 5)
        .forEach(label => {
          const confidence = Math.round(label.score * 100);
          description += `‚Ä¢ ${label.description} (${confidence}% seguro)\n`;
        });
      description += '\n';
    }

    // TERCERO: Objetos espec√≠ficos
    if (result.objects && result.objects.length > 0) {
      description += 'üéØ **OBJETOS ESPEC√çFICOS:**\n';
      result.objects
        .filter(obj => obj.score > 0.5)
        .slice(0, 3)
        .forEach(obj => {
          const confidence = Math.round(obj.score * 100);
          description += `‚Ä¢ ${obj.name} (${confidence}% seguro)\n`;
        });
    }

    console.log('‚úÖ [VISION] Descripci√≥n generada:', description);
    return description;
  }

  // Funci√≥n para respuestas conversacionales con Gemini
  static async getChatResponse(message: string): Promise<string> {
    try {
      console.log('ü§ñ [GEMINI] Iniciando getChatResponse...');
      console.log('üìù [GEMINI] Mensaje recibido:', message.substring(0, 200) + '...');
      
      if (!this.API_KEY) {
        console.error('‚ùå [GEMINI] API key no configurada');
        throw new Error('Google API key no configurada');
      }
      
      console.log('‚úÖ [GEMINI] API key disponible');

      const requestBody = {
        contents: [
          {
            parts: [
              {
                text: `Eres un asistente especializado en an√°lisis de planes de trabajo y horarios laborales. Tu funci√≥n principal es:

1. üìÖ Analizar im√°genes de calendarios, horarios y planes de trabajo
2. üîç Extraer informaci√≥n sobre:
   - D√≠as de trabajo y horarios
   - D√≠as libres y descansos
   - Vacaciones y per√≠odos de ausencia
   - Turnos y horarios espec√≠ficos
3. üë• Detectar m√∫ltiples personas en planes de trabajo y preguntar espec√≠ficamente de qui√©n extraer los datos
4. üìä Presentar la informaci√≥n de forma clara y organizada
5. üíº Ayudar con consultas relacionadas con planificaci√≥n laboral

IMPORTANTE: Si detectas varios nombres en un plan de trabajo, SIEMPRE pregunta de cu√°l persona espec√≠fica debe extraer los horarios antes de proceder.

Responde siempre en espa√±ol de manera clara y profesional.

Usuario: ${message}`
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 1024,
        },
        safetySettings: [
          {
            category: "HARM_CATEGORY_HARASSMENT",
            threshold: "BLOCK_MEDIUM_AND_ABOVE"
          },
          {
            category: "HARM_CATEGORY_HATE_SPEECH",
            threshold: "BLOCK_MEDIUM_AND_ABOVE"
          },
          {
            category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold: "BLOCK_MEDIUM_AND_ABOVE"
          },
          {
            category: "HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold: "BLOCK_MEDIUM_AND_ABOVE"
          }
        ]
      };

      console.log('üì§ [GEMINI] Enviando request a Gemini API...');
      console.log('üîó [GEMINI] URL:', this.GEMINI_BASE_URL);
      console.log('üì¶ [GEMINI] Request body:', JSON.stringify(requestBody, null, 2));

      const response = await fetch(`${this.GEMINI_BASE_URL}?key=${this.API_KEY}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      console.log('üì° [GEMINI] Response status:', response.status);
      console.log('üì° [GEMINI] Response headers:', Object.fromEntries(response.headers.entries()));

      if (!response.ok) {
        const errorData = await response.json();
        console.error('‚ùå [GEMINI] Error completo:', errorData);
        throw new Error(`Error en Gemini API: ${response.status} - ${errorData.error?.message || 'Error desconocido'}`);
      }

      const data = await response.json();
      console.log('üì• [GEMINI] Response data completa:', JSON.stringify(data, null, 2));

      if (data.candidates && data.candidates.length > 0) {
        const candidate = data.candidates[0];
        console.log('üéØ [GEMINI] Candidate encontrado:', candidate);
        
        if (candidate.content && candidate.content.parts && candidate.content.parts.length > 0) {
          const responseText = candidate.content.parts[0].text;
          console.log('‚úÖ [GEMINI] Respuesta exitosa:', responseText);
          return responseText;
        } else {
          console.warn('‚ö†Ô∏è [GEMINI] Candidate sin contenido v√°lido');
        }
      } else {
        console.warn('‚ö†Ô∏è [GEMINI] No hay candidates en la respuesta');
      }

      console.log('üîÑ [GEMINI] Retornando respuesta por defecto');
      return 'Lo siento, no pude generar una respuesta en este momento.';
    } catch (error) {
      console.error('Error en Gemini API:', error);
      return 'Lo siento, hubo un problema al procesar tu mensaje. ¬øPuedes intentar de nuevo?';
    }
  }

  // Funci√≥n para analizar imagen directamente con Gemini Vision
  static async analyzeImageWithGeminiVision(imageUri: string, userMessage: string): Promise<string> {
    try {
      console.log('üëÅÔ∏è [GEMINI-VISION] Iniciando an√°lisis con Gemini Vision...');
      console.log('üì± [GEMINI-VISION] Image URI:', imageUri);
      console.log('üí¨ [GEMINI-VISION] User message:', userMessage);
      
      if (!this.API_KEY) {
        throw new Error('Google API key no configurada');
      }

      // Convertir imagen a base64
      const base64Image = await FileSystem.readAsStringAsync(imageUri, {
        encoding: FileSystem.EncodingType.Base64,
      });
      console.log('üñºÔ∏è [GEMINI-VISION] Imagen convertida a base64');

      const requestBody = {
        contents: [
          {
            parts: [
              {
                text: `Eres un experto en an√°lisis de planes de trabajo y horarios laborales.

AN√ÅLISIS DE PLAN DE TRABAJO - ${userMessage || 'Analiza este plan de trabajo'}

INSTRUCCIONES ESPEC√çFICAS:

${userMessage.includes('Extrae los horarios espec√≠ficamente de') ? 
  `üéØ AN√ÅLISIS ESPEC√çFICO: ${userMessage}

Analiza la imagen y extrae SOLO los datos de la persona especificada:
1. üìÖ D√≠as de trabajo de esa persona y sus horarios
2. üèñÔ∏è D√≠as libres, descansos de esa persona (OFF, LIBRE, etc.)
3. üèùÔ∏è Vacaciones de esa persona
4. üïê Horarios espec√≠ficos de esa persona

FORMATO DE RESPUESTA:
- PERSONA: [nombre especificado]
- D√çAS DE TRABAJO: [d√≠as y horarios espec√≠ficos de esa persona]
- D√çAS LIBRES: [d√≠as libres de esa persona]
- VACACIONES: [vacaciones de esa persona]
- OBSERVACIONES: [detalles espec√≠ficos de esa persona]` 
  : 
  `PASO 1 - DETECCI√ìN DE PERSONAS:
üîç Identifica si hay M√öLTIPLES NOMBRES/PERSONAS en este plan de trabajo.

SI HAY VARIOS NOMBRES:
- Lista todos los nombres que veas
- Pregunta: "Veo varios nombres en este plan: [lista nombres]. ¬øDe cu√°l persona quieres que extraiga los horarios?"
- NO extraigas datos hasta que el usuario especifique

SI HAY UN SOLO NOMBRE O NING√öN NOMBRE ESPEC√çFICO:
PASO 2 - EXTRACCI√ìN DE DATOS:
Analiza la imagen y extrae:
1. üìÖ D√≠as de trabajo (lunes, martes, mi√©rcoles, etc.) y sus horarios
2. üèñÔ∏è D√≠as libres, descansos (OFF, LIBRE, descanso, etc.)
3. üèùÔ∏è Vacaciones o per√≠odos libres (VACACIONES, holidays, etc.)
4. üïê Horarios espec√≠ficos (8:00-16:00, 9:00-17:00, ma√±ana, tarde, noche, etc.)
5. üë§ Nombres de personas si est√°n visibles

FORMATO DE RESPUESTA:
- PERSONA: [nombre si est√° visible, sino "Plan general"]
- D√çAS DE TRABAJO: [lista d√≠as y horarios]
- D√çAS LIBRES: [lista d√≠as de descanso]
- VACACIONES: [per√≠odos de vacaciones]
- OBSERVACIONES: [turnos, notas especiales, etc.]`}

Responde en espa√±ol de forma clara y estructurada y comprimida mensajes no muy largos.`
              },
              {
                inline_data: {
                  mime_type: "image/jpeg",
                  data: base64Image
                }
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 1024,
        }
      };

      console.log('üì§ [GEMINI-VISION] Enviando request...');
      const response = await fetch(`${this.GEMINI_BASE_URL}?key=${this.API_KEY}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      console.log('üì° [GEMINI-VISION] Response status:', response.status);

      if (!response.ok) {
        const errorData = await response.json();
        console.error('‚ùå [GEMINI-VISION] Error:', errorData);
        throw new Error(`Error en Gemini Vision: ${response.status} - ${errorData.error?.message || 'Error desconocido'}`);
      }

      const data = await response.json();
      console.log('üì• [GEMINI-VISION] Response data:', JSON.stringify(data, null, 2));

      if (data.candidates && data.candidates.length > 0) {
        const candidate = data.candidates[0];
        if (candidate.content && candidate.content.parts && candidate.content.parts.length > 0) {
          const responseText = candidate.content.parts[0].text;
          console.log('‚úÖ [GEMINI-VISION] Respuesta exitosa:', responseText);
          return responseText;
        }
      }

      console.log('‚ö†Ô∏è [GEMINI-VISION] Respuesta vac√≠a, usando fallback');
      return 'No pude analizar la imagen del plan de trabajo. Por favor, intenta con una imagen m√°s clara.';

    } catch (error) {
      console.error('‚ùå [GEMINI-VISION] Error:', error);
      return 'Lo siento, hubo un problema al analizar la imagen con Gemini Vision. Intentar√© con el m√©todo alternativo.';
    }
  }

  // Funci√≥n para respuesta con contexto conversacional
  static async getChatResponseWithContext(message: string, conversationHistory: any[], currentImage?: string): Promise<string> {
    try {
      console.log('üß† [CONTEXTO] Iniciando respuesta con contexto conversacional...');
      console.log('üìö [CONTEXTO] Historial de conversaci√≥n:', conversationHistory);
      console.log('üñºÔ∏è [CONTEXTO] Imagen actual:', currentImage ? 'S√≠' : 'No');
      
      if (!this.API_KEY) {
        throw new Error('Google API key no configurada');
      }

      // Crear contexto de conversaci√≥n
      let contextPrompt = `Eres un asistente especializado en an√°lisis de planes de trabajo y horarios laborales.

CONTEXTO DE LA CONVERSACI√ìN:
`;

      // Agregar historial de conversaci√≥n
      if (conversationHistory.length > 0) {
        contextPrompt += `\nHISTORIAL DE MENSAJES RECIENTES:\n`;
        conversationHistory.forEach((msg) => {
          const mediaIndicator = msg.hasImage ? ' [CON IMAGEN]' : msg.hasDocument ? ' [CON DOCUMENTO PDF]' : '';
          contextPrompt += `${msg.role.toUpperCase()}: ${msg.content}${mediaIndicator}\n`;
        });
      }

      // Si hay imagen actual, mencionarla
      if (currentImage) {
        contextPrompt += `\nIMAGEN ACTIVA: Hay una imagen de plan de trabajo que fue analizada previamente y sigue siendo relevante para las consultas del usuario.\n`;
      }

      contextPrompt += `\nINSTRUCCIONES:
1. üß† Usa el contexto de la conversaci√≥n para entender qu√© informaci√≥n necesita el usuario
2. üìã Si se mencionaron nombres en mensajes anteriores, recuerda cu√°les eran
3. üîç Si el usuario est√° pidiendo informaci√≥n espec√≠fica de una persona mencionada antes, proporciona esa informaci√≥n
4. üí¨ Mant√©n coherencia con las respuestas anteriores
5. üì∏ Si hay una imagen activa, asume que las preguntas se refieren a esa imagen

MENSAJE ACTUAL DEL USUARIO: ${message}

Responde de manera coherente con el contexto de la conversaci√≥n.`;

      const requestBody = {
        contents: [
          {
            parts: [
              {
                text: contextPrompt
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 1024,
        },
        safetySettings: [
          {
            category: "HARM_CATEGORY_HARASSMENT",
            threshold: "BLOCK_MEDIUM_AND_ABOVE"
          },
          {
            category: "HARM_CATEGORY_HATE_SPEECH",
            threshold: "BLOCK_MEDIUM_AND_ABOVE"
          },
          {
            category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold: "BLOCK_MEDIUM_AND_ABOVE"
          },
          {
            category: "HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold: "BLOCK_MEDIUM_AND_ABOVE"
          }
        ]
      };

      console.log('üì§ [CONTEXTO] Enviando request con contexto...');
      const response = await fetch(`${this.GEMINI_BASE_URL}?key=${this.API_KEY}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorData = await response.json();
        console.error('‚ùå [CONTEXTO] Error:', errorData);
        throw new Error(`Error en Gemini API: ${response.status} - ${errorData.error?.message || 'Error desconocido'}`);
      }

      const data = await response.json();
      console.log('üì• [CONTEXTO] Response data:', JSON.stringify(data, null, 2));

      if (data.candidates && data.candidates.length > 0) {
        const candidate = data.candidates[0];
        if (candidate.content && candidate.content.parts && candidate.content.parts.length > 0) {
          const responseText = candidate.content.parts[0].text;
          console.log('‚úÖ [CONTEXTO] Respuesta con contexto exitosa:', responseText);
          return responseText;
        }
      }

      return 'Lo siento, no pude generar una respuesta en este momento.';
    } catch (error) {
      console.error('‚ùå [CONTEXTO] Error:', error);
      return 'Lo siento, hubo un problema al procesar tu mensaje con contexto.';
    }
  }

  // Funci√≥n para analizar documentos PDF
  static async analyzePDFDocument(documentUri: string, documentName: string, userMessage: string): Promise<string> {
    try {
      console.log('üìÑ [PDF] Iniciando an√°lisis de documento PDF...');
      console.log('üìÅ [PDF] Document URI:', documentUri);
      console.log('üìã [PDF] Document name:', documentName);
      console.log('üí¨ [PDF] User message:', userMessage);
      
      if (!this.API_KEY) {
        throw new Error('Google API key no configurada');
      }

      // Convertir PDF a base64
      const base64Document = await FileSystem.readAsStringAsync(documentUri, {
        encoding: FileSystem.EncodingType.Base64,
      });
      console.log('üìÑ [PDF] Documento convertido a base64');

      const requestBody = {
        contents: [
          {
            parts: [
              {
                text: `Eres un experto en an√°lisis de planes de trabajo y horarios laborales.

AN√ÅLISIS DE DOCUMENTO PDF - ${userMessage || 'Analiza este documento'}

El usuario subi√≥ un documento PDF llamado "${documentName}".

INSTRUCCIONES ESPEC√çFICAS:

${userMessage.includes('Extrae los horarios espec√≠ficamente de') ? 
  `üéØ AN√ÅLISIS ESPEC√çFICO: ${userMessage}

Lee el documento PDF y extrae SOLO los datos de la persona especificada:
1. üìÖ D√≠as de trabajo de esa persona y sus horarios
2. üèñÔ∏è D√≠as libres, descansos de esa persona (OFF, LIBRE, etc.)
3. üèùÔ∏è Vacaciones de esa persona
4. üïê Horarios espec√≠ficos de esa persona

FORMATO DE RESPUESTA:
- DOCUMENTO: ${documentName}
- PERSONA: [nombre especificado en el mensaje]
- D√çAS DE TRABAJO: [d√≠as y horarios espec√≠ficos de esa persona]
- D√çAS LIBRES: [d√≠as libres de esa persona]
- VACACIONES: [vacaciones de esa persona]
- OBSERVACIONES: [detalles espec√≠ficos de esa persona]` 
  : 
  `PASO 1 - DETECCI√ìN DE PERSONAS:
üîç Lee el contenido del PDF e identifica si hay M√öLTIPLES NOMBRES/PERSONAS en este plan de trabajo.

SI HAY VARIOS NOMBRES:
- Lista todos los nombres que encuentres
- Pregunta: "Veo varios nombres en este plan: [lista nombres]. ¬øDe cu√°l persona quieres que extraiga los horarios?"
- NO extraigas datos hasta que el usuario especifique

SI HAY UN SOLO NOMBRE O NING√öN NOMBRE ESPEC√çFICO:
PASO 2 - EXTRACCI√ìN DE DATOS:
Lee el documento PDF y extrae:
1. üìÖ D√≠as de trabajo (lunes, martes, mi√©rcoles, etc.) y sus horarios
2. üèñÔ∏è D√≠as libres, descansos (OFF, LIBRE, descanso, etc.)
3. üèùÔ∏è Vacaciones o per√≠odos libres (VACACIONES, holidays, etc.)
4. üïê Horarios espec√≠ficos (8:00-16:00, 9:00-17:00, ma√±ana, tarde, noche, etc.)
5. üë§ Nombres de personas si est√°n visibles

FORMATO DE RESPUESTA:
- DOCUMENTO: ${documentName}
- PERSONA: [nombre si est√° visible, sino "Plan general"]
- D√çAS DE TRABAJO: [lista d√≠as y horarios]
- D√çAS LIBRES: [lista d√≠as de descanso]
- VACACIONES: [per√≠odos de vacaciones]
- OBSERVACIONES: [turnos, notas especiales, etc.]`}

Responde en espa√±ol de forma clara y estructurada.`
              },
              {
                inline_data: {
                  mime_type: "application/pdf",
                  data: base64Document
                }
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 1024,
        }
      };

      console.log('üì§ [PDF] Enviando request...');
      const response = await fetch(`${this.GEMINI_BASE_URL}?key=${this.API_KEY}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      console.log('üì° [PDF] Response status:', response.status);

      if (!response.ok) {
        const errorData = await response.json();
        console.error('‚ùå [PDF] Error:', errorData);
        throw new Error(`Error en an√°lisis de PDF: ${response.status} - ${errorData.error?.message || 'Error desconocido'}`);
      }

      const data = await response.json();
      console.log('üì• [PDF] Response data:', JSON.stringify(data, null, 2));

      if (data.candidates && data.candidates.length > 0) {
        const candidate = data.candidates[0];
        if (candidate.content && candidate.content.parts && candidate.content.parts.length > 0) {
          const responseText = candidate.content.parts[0].text;
          console.log('‚úÖ [PDF] Respuesta exitosa:', responseText);
          return responseText;
        }
      }

      console.log('‚ö†Ô∏è [PDF] Respuesta vac√≠a, usando fallback');
      return `He recibido el documento PDF "${documentName}" pero no pude procesarlo completamente. Los PDFs a veces requieren procesamiento especial. ¬øPodr√≠as intentar convertirlo a imagen o enviar una captura de pantalla del plan de trabajo?`;

    } catch (error) {
      console.error('‚ùå [PDF] Error:', error);
      return `Lo siento, hubo un problema al analizar el documento PDF "${documentName}". Los PDFs pueden requerir procesamiento especial. Como alternativa, puedes tomar una captura de pantalla del documento y enviarla como imagen.`;
    }
  }

  // Funci√≥n h√≠brida que usa Gemini Vision primero, y Vision API como fallback
  static async analyzeWorkPlan(imageUri: string, userMessage: string): Promise<string> {
    try {
      console.log('üîÄ [H√çBRIDO] Iniciando an√°lisis h√≠brido de plan de trabajo...');
      
      // M√âTODO 1: Intentar con Gemini Vision primero (m√°s inteligente)
      console.log('üëÅÔ∏è [H√çBRIDO] Probando con Gemini Vision...');
      try {
        const geminiResult = await this.analyzeImageWithGeminiVision(imageUri, userMessage);
        
        // Si Gemini Vision funcion√≥ y no devolvi√≥ un mensaje de error
        if (geminiResult && !geminiResult.includes('Lo siento, hubo un problema')) {
          console.log('‚úÖ [H√çBRIDO] Gemini Vision exitoso!');
          return geminiResult;
        }
      } catch (error) {
        console.log('‚ö†Ô∏è [H√çBRIDO] Gemini Vision fall√≥, usando Vision API...');
        console.error('üîç [H√çBRIDO] Error Gemini Vision:', error);
      }

      // M√âTODO 2: Fallback a Vision API + Gemini texto
      console.log('üîÑ [H√çBRIDO] Usando Vision API + Gemini como fallback...');
      return await this.analyzeImageWithContext(imageUri, userMessage);

    } catch (error) {
      console.error('‚ùå [H√çBRIDO] Error en an√°lisis h√≠brido:', error);
      return 'Lo siento, hubo un problema al analizar el plan de trabajo. Por favor, intenta con una imagen m√°s clara o en mejor calidad.';
    }
  }

  // Funci√≥n combinada para an√°lisis de imagen + respuesta conversacional (Vision API)
  static async analyzeImageWithContext(imageUri: string, userMessage: string): Promise<string> {
    try {
      console.log('üñºÔ∏è [VISION-API] Iniciando analyzeImageWithContext...');
      console.log('üì± [VISION-API] Image URI:', imageUri);
      console.log('üí¨ [VISION-API] User message:', userMessage);
      
      // Primero analizar la imagen
      console.log('üîç [VISION-API] Analizando imagen...');
      const imageAnalysis = await this.getImageDescription(imageUri);
      console.log('üìä [VISION-API] An√°lisis de imagen completo:', imageAnalysis);
      
      // Luego generar respuesta conversacional basada en el an√°lisis y el mensaje del usuario
      const contextMessage = `AN√ÅLISIS DE PLAN DE TRABAJO

El usuario envi√≥ una imagen de un plan/horario de trabajo y escribi√≥: "${userMessage}"

INFORMACI√ìN EXTRA√çDA DE LA IMAGEN:
${imageAnalysis}

INSTRUCCIONES PARA EL AN√ÅLISIS:

IMPORTANTE: Analiza DIRECTAMENTE el texto extra√≠do de la imagen (secci√≥n "TEXTO DETECTADO").

PASO 1 - DETECCI√ìN DE PERSONAS:
üîç Busca NOMBRES DE PERSONAS en el texto extra√≠do.

SI HAY VARIOS NOMBRES:
- Lista todos los nombres que encuentres en el texto
- Pregunta: "Veo varios nombres en este plan: [lista nombres]. ¬øDe cu√°l persona quieres que extraiga los horarios?"
- NO extraigas datos hasta que el usuario especifique

SI HAY UN SOLO NOMBRE O EL USUARIO YA ESPECIFIC√ì:
PASO 2 - EXTRACCI√ìN DE DATOS:
Analiza el TEXTO EXTRA√çDO para identificar:
1. üìÖ D√≠as de trabajo (lunes, martes, etc.) y horarios
2. üèñÔ∏è D√≠as libres, descansos, "OFF", "LIBRE", etc.
3. üèñÔ∏è Vacaciones, per√≠odos libres, "VACACIONES", etc.
4. üïê Horarios espec√≠ficos (8:00-16:00, ma√±ana, tarde, etc.)

FORMATO DE RESPUESTA:
- PERSONA: [nombre si est√° visible]
- D√çAS DE TRABAJO: [extrae del texto]
- D√çAS LIBRES: [extrae del texto]
- VACACIONES: [extrae del texto] 
- OBSERVACIONES: [detalles adicionales del texto]

Si no hay texto legible, ind√≠calo claramente.`;

      console.log('üìù [IMAGEN] Context message generado:', contextMessage);
      console.log('üöÄ [IMAGEN] Enviando a Gemini para respuesta final...');
      
      const finalResponse = await this.getChatResponse(contextMessage);
      console.log('‚úÖ [IMAGEN] Respuesta final recibida:', finalResponse);
      
      return finalResponse;
    } catch (error) {
      console.error('Error en an√°lisis combinado:', error);
      return 'Lo siento, hubo un problema al analizar la imagen y generar una respuesta.';
    }
  }
}